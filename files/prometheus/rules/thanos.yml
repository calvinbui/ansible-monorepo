---

groups:
  - name: thanos-compactor
    rules:
      - alert: ThanosCompactorMultipleRunning
        expr: sum by (job) (up{job=~".*thanos-compact.*"}) > 1
        for: 5m
        annotations:
          summary: Thanos Compactor Multiple Running
          description: "No more than one Thanos Compact instance should be running at once. There are {{$value}} instances running"

      - alert: ThanosCompactorHalted
        expr: thanos_compact_halted{job=~".*thanos-compact.*"} == 1
        for: 5m
        annotations:
          summary: Thanos Compactor Halted
          description: "Thanos Compact has failed to run and now is halted"

      - alert: ThanosCompactorHighCompactionFailures
        expr: (sum by (job) (rate(thanos_compact_group_compactions_failures_total{job=~".*thanos-compact.*"}[5m])) / sum by (job) (rate(thanos_compact_group_compactions_total{job=~".*thanos-compact.*"}[5m])) * 100 > 5)
        for: 15m
        annotations:
          summary: Thanos Compactor High Compaction Failures
          description: "Thanos Compact is failing to execute {{$value | humanize}}% of compactions"

      - alert: ThanosCompactBucketHighOperationFailures
        expr: (sum by (job) (rate(thanos_objstore_bucket_operation_failures_total{job=~".*thanos-compact.*"}[5m])) / sum by (job) (rate(thanos_objstore_bucket_operations_total{job=~".*thanos-compact.*"}[5m])) * 100 > 5)
        for: 15m
        annotations:
          summary: Thanos Compact Bucket High Operation Failures
          description: "Thanos Compact Bucket is failing to execute {{$value | humanize}}% of operations"

  - name: thanos-query
    rules:
      - alert: ThanosQueryHttpRequestQueryErrorRateHigh
        expr: (sum by (job) (rate(http_requests_total{code=~"5..", job=~".*thanos-query.*", handler="query"}[5m]))/  sum by (job) (rate(http_requests_total{job=~".*thanos-query.*", handler="query"}[5m]))) * 100 > 5
        for: 5m
        annotations:
          summary: Thanos Query Http Request Query Error Rate High
          description: "Thanos Query is failing to handle {{$value | humanize}}% of \"query\" requests"

      - alert: ThanosQueryHttpRequestQueryRangeErrorRateHigh
        expr: (sum by (job) (rate(http_requests_total{code=~"5..", job=~".*thanos-query.*", handler="query_range"}[5m]))/  sum by (job) (rate(http_requests_total{job=~".*thanos-query.*", handler="query_range"}[5m]))) * 100 > 5
        for: 5m
        annotations:
          summary: Thanos Query Http Request Query Range Error Rate High
          description: "Thanos Query is failing to handle {{$value | humanize}}% of \"query_range\" requests"

      - alert: ThanosQueryGrpcServerErrorRate
        expr: (sum by (job) (rate(grpc_server_handled_total{grpc_code=~"Unknown|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded", job=~".*thanos-query.*"}[5m]))/  sum by (job) (rate(grpc_server_started_total{job=~".*thanos-query.*"}[5m])) * 100 > 5)
        for: 5m
        annotations:
          summary: Thanos Query Grpc Server Error Rate
          description: "Thanos Query is failing to handle {{$value | humanize}}% of requests"

      - alert: ThanosQueryGrpcClientErrorRate
        expr: (sum by (job) (rate(grpc_client_handled_total{grpc_code!="OK", job=~".*thanos-query.*"}[5m])) / sum by (job) (rate(grpc_client_started_total{job=~".*thanos-query.*"}[5m]))) * 100 > 5
        for: 5m
        annotations:
          summary: Thanos Query Grpc Client Error Rate
          description: "Thanos Query is failing to send {{$value | humanize}}% of requests"

      - alert: ThanosQueryHighDNSFailures
        expr: (sum by (job) (rate(thanos_query_store_apis_dns_failures_total{job=~".*thanos-query.*"}[5m])) / sum by (job) (rate(thanos_query_store_apis_dns_lookups_total{job=~".*thanos-query.*"}[5m]))) * 100 > 1
        for: 15m
        annotations:
          summary: Thanos Query High D N S Failures
          description: "Thanos Query have {{$value | humanize}}% of failing DNS queries for store endpoints"

      - alert: ThanosQueryInstantLatencyHigh
        expr: (histogram_quantile(0.99, sum by (job, le) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query.*", handler="query"}[5m]))) > 40 and sum by (job) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query.*", handler="query"}[5m])) > 0)
        for: 10m
        annotations:
          summary: Thanos Query Instant Latency High
          description: "Thanos Query has a 99th percentile latency of {{$value}} seconds for instant queries"

      - alert: ThanosQueryRangeLatencyHigh
        expr: (histogram_quantile(0.99, sum by (job, le) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query.*", handler="query_range"}[5m]))) > 90 and sum by (job) (rate(http_request_duration_seconds_count{job=~".*thanos-query.*", handler="query_range"}[5m])) > 0)
        for: 10m
        annotations:
          summary: Thanos Query Range Latency High
          description: "Thanos Query has a 99th percentile latency of {{$value}} seconds for range queries"

      - alert: ThanosQueryOverload
        expr: (max_over_time(thanos_query_concurrent_gate_queries_max[5m]) - avg_over_time(thanos_query_concurrent_gate_queries_in_flight[5m]) < 1)
        for: 15m
        annotations:
          summary: Thanos Query Overload
          description: "Thanos Query has been overloaded for more than 15 minutes. This may be a symptom of excessive simultanous complex requests, low performance of the Prometheus API, or failures within these components. Assess the health of the Thanos query instances, the connnected Prometheus instances, look for potential senders of these requests and then contact support"

  - name: thanos-sidecar
    rules:
      - alert: ThanosSidecarBucketOperationsFailed
        expr: sum by (job, instance) (rate(thanos_objstore_bucket_operation_failures_total{job=~".*thanos-sidecar.*"}[5m])) > 0
        for: 5m
        annotations:
          summary: Thanos Sidecar Bucket Operations Failed
          description: "Thanos Sidecar bucket operations are failin"

      - alert: ThanosSidecarNoConnectionToStartedPrometheus
        expr: thanos_sidecar_prometheus_up{job=~".*thanos-sidecar.*"} == 0 and on (namespace, pod)prometheus_tsdb_data_replay_duration_seconds != 0
        for: 5m
        annotations:
          summary: Thanos Sidecar No Connection To Started Prometheus
          description: "Thanos Sidecar is unhealthy"

  - name: thanos-store
    rules:
      - alert: ThanosStoreGrpcErrorRate
        expr: (sum by (job) (rate(grpc_server_handled_total{grpc_code=~"Unknown|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded", job=~".*thanos-store.*"}[5m]))/  sum by (job) (rate(grpc_server_started_total{job=~".*thanos-store.*"}[5m])) * 100 > 5)
        for: 5m
        annotations:
          summary: Thanos Store Grpc Error Rate
          description: "Thanos Store is failing to handle {{$value | humanize}}% of requests"

      - alert: ThanosStoreSeriesGateLatencyHigh
        expr: (histogram_quantile(0.99, sum by (job, le) (rate(thanos_bucket_store_series_gate_duration_seconds_bucket{job=~".*thanos-store.*"}[5m]))) > 2 and sum by (job) (rate(thanos_bucket_store_series_gate_duration_seconds_count{job=~".*thanos-store.*"}[5m])) > 0)
        for: 10m
        annotations:
          summary: Thanos Store Series Gate Latency High
          description: "Thanos Store has a 99th percentile latency of {{$value}} seconds for store series gate requests"

      - alert: ThanosStoreBucketHighOperationFailures
        expr: (sum by (job) (rate(thanos_objstore_bucket_operation_failures_total{job=~".*thanos-store.*"}[5m])) / sum by (job) (rate(thanos_objstore_bucket_operations_total{job=~".*thanos-store.*"}[5m])) * 100 > 5)
        for: 15m
        annotations:
          summary: Thanos Store Bucket High Operation Failures
          description: "Thanos Store Bucket is failing to execute {{$value | humanize}}% of operations"

      - alert: ThanosStoreObjstoreOperationLatencyHigh
        expr: (histogram_quantile(0.99, sum by (job, le) (rate(thanos_objstore_bucket_operation_duration_seconds_bucket{job=~".*thanos-store.*"}[5m]))) > 2 and  sum by (job) (rate(thanos_objstore_bucket_operation_duration_seconds_count{job=~".*thanos-store.*"}[5m])) > 0)
        for: 10m
        annotations:
          summary: Thanos Store Objstore Operation Latency High
          description: "Thanos Store Bucket has a 99th percentile latency of {{$value}} seconds for the bucket operations"
